{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9cvXkGIWXj4"
      },
      "source": [
        "# KoSAIM 2025 Summer School\n",
        "\n",
        "## Fine-tuning a clinical domain LLM\n",
        "\n",
        "- 강사: 김지호(jiho.kim@kaist.ac.kr), 임수정(sujeongim@kaist.ac.kr)\n",
        "\n",
        "- 발표자료: https://docs.google.com/presentation/d/1KGcN4iYkw7GH6zZinSW2o9mFWYXmtwpKfkA5Bcc2FDs/edit?usp=sharing\n",
        "\n",
        "- 레퍼런스: https://github.com/starmpcc/KAIA-LLM-FT-2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9fzdBAodxFb"
      },
      "source": [
        "## [Step 1] 환경 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패키지 설치"
      ],
      "metadata": {
        "id": "GRQ7QKmhe8c_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M13VmfZgAPiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate  peft  bitsandbytes  transformers trl  numpy einops gradio nltk triton gcsfs fsspec"
      ],
      "metadata": {
        "id": "Ffnt_Cu9hIhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리 가져오기"
      ],
      "metadata": {
        "id": "sY4JzUxDfBOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyq7qXBK5hrq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig, DataCollatorForCompletionOnlyLM\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVgms3ygcjJ-"
      },
      "source": [
        "## [Step 2] 사전 학습된 모델 (및 토크나이저) 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 가져오기"
      ],
      "metadata": {
        "id": "I4roEZJHfHja"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ8sYecacjJ_"
      },
      "outputs": [],
      "source": [
        "# Quantization Config 정의\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n",
        "# 사전학습된 기본 모델 가져오기\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    force_download=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 살펴보기"
      ],
      "metadata": {
        "id": "M9Q5u7W69pm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (양자화된) 레이어 살펴보기\n",
        "model.model.layers[0].mlp.fc1.weight"
      ],
      "metadata": {
        "id": "Vr0yKycw9esA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (양자회된) 레이어 데이터 타입 살펴보기\n",
        "model.model.layers[0].mlp.fc1.weight.dtype"
      ],
      "metadata": {
        "id": "ktTrqjIN95ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 개수 확인\n",
        "sum([p.numel() for p in model.parameters()])"
      ],
      "metadata": {
        "id": "w7i7PD1j97oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cuda memory 체크\n",
        "print(torch.cuda.memory_summary())"
      ],
      "metadata": {
        "id": "kM_PV0VO9_RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이저 가져오기"
      ],
      "metadata": {
        "id": "9jfxsQc4fNta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델에 맞는 토크나이저 가져오기\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/phi-2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_sight = \"right\""
      ],
      "metadata": {
        "id": "ncMyOw8TfMLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이저 살펴보기"
      ],
      "metadata": {
        "id": "FiDpN3sU9nHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer vocab 개수 확인\n",
        "len(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "5bI2VR3B9pBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer vocab 확인\n",
        "tokenizer.vocab"
      ],
      "metadata": {
        "id": "LIgtDZQN-bwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer special token 확인\n",
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "id": "z6fcNHR6-XMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer로 tokenize 해보기\n",
        "tokenizer.tokenize(\"Hi, my name is John.\")"
      ],
      "metadata": {
        "id": "lv59kLYr-bSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer로 encoding 해보기\n",
        "tokenizer.encode(\"Hi, my name is John.\")"
      ],
      "metadata": {
        "id": "J-efM3L--nlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer로 encoding 해보기 (2)\n",
        "tokenizer(\"Hi, my name is John.\")"
      ],
      "metadata": {
        "id": "nFzLuX7f-yGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer로 encoding -> decoding 해보기\n",
        "sample_text = \"Hi, my name is John.\"\n",
        "encoded_text = tokenizer.encode(sample_text)\n",
        "decoded_text = tokenizer.decode(encoded_text)\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "id": "XUuYbkN8-rGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD9KPe_XeeR6"
      },
      "source": [
        "## [Step 3] Asclepius-Synthetic-Clinical-Notes 데이터 확인하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFS_d9khhY9"
      },
      "source": [
        "- 데이터 링크 : https://huggingface.co/datasets/starmpcc/Asclepius-Synthetic-Clinical-Notes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기"
      ],
      "metadata": {
        "id": "iUBvtBqod78Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTvYIHkicjKA"
      },
      "outputs": [],
      "source": [
        "# Asclepius-Synthetic-Clinical-Notes 원본 데이터셋 가져오기\n",
        "dataset = load_dataset(\"starmpcc/Asclepius-Synthetic-Clinical-Notes\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 체크\n",
        "dataset"
      ],
      "metadata": {
        "id": "D7D7Dd8j_EMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvQZR6kFcjKA"
      },
      "outputs": [],
      "source": [
        "# 노트 길이 확인\n",
        "plt.hist([len(sample['note']) for sample in dataset['train']])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSVmkuP3cjKA"
      },
      "outputs": [],
      "source": [
        "# 필터링: 노트의 길이가 1500보다 작은 경우\n",
        "dataset = dataset.filter(lambda x: [len(i)<1500 for i in x['note']], batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 체크 (필터링 이후)\n",
        "dataset"
      ],
      "metadata": {
        "id": "jVZu6yEP_Gm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pJHYkD2cjKA"
      },
      "outputs": [],
      "source": [
        "# 필터링 함수 정의\n",
        "def prompt_shorter_than(samples):\n",
        "    # 각 샘플의 'note', 'question', 'answer' 필드를 공백으로 연결하여 하나의 문자열로 결합\n",
        "    concatenated = [\" \".join([i, j, k]) for i, j, k in zip(samples['note'], samples['question'], samples['answer'])]\n",
        "    # 결합된 문자열을 토크나이저로 토큰화하고, 토큰 길이가 320 이하인지를 확인하여 리스트로 반환\n",
        "    return [len(i)<=320 for i in tokenizer(concatenated)['input_ids']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHpzwsywcjKA"
      },
      "outputs": [],
      "source": [
        "# 필터링: 토크나이저\n",
        "dataset = dataset.filter(prompt_shorter_than, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 체크 (필터링 이후)\n",
        "dataset"
      ],
      "metadata": {
        "id": "Nouepitm_Hsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsAFMG-wqzo8"
      },
      "source": [
        "### 데이터 탐색하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJxznOdbVdu6"
      },
      "outputs": [],
      "source": [
        "# train 데이터 구성\n",
        "print(dataset['train'])\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt18uzy1cjKA"
      },
      "outputs": [],
      "source": [
        "# 샘플 데이터 확인\n",
        "sample_idx = 0\n",
        "sample_data = dataset['train'][sample_idx]\n",
        "sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E9vP1KEq4wu"
      },
      "outputs": [],
      "source": [
        "# 데이터셋을 DataFrame으로 변환\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# 데이터프레임 일부 출력(5개만 출력)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT_-yc2ounCq"
      },
      "outputs": [],
      "source": [
        "# Task 종류별 개수\n",
        "df.groupby('task').size().plot(kind='barh', color=plt.cm.Set3.colors)\n",
        "plt.xlabel('Number of Tasks')\n",
        "plt.ylabel('Task Type')\n",
        "plt.title('Number of Tasks')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaWbAf7xv8gV"
      },
      "outputs": [],
      "source": [
        "# Task 분포\n",
        "df['task'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=plt.cm.Set3.colors)\n",
        "plt.ylabel('')\n",
        "plt.title('Distribution of Tasks')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFdQq9wg-ojz"
      },
      "source": [
        "## [Step 4] 학습 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ6V43pqcjKB"
      },
      "source": [
        "### 프롬프트 데이터 전처리 함수 정의 (`formatting_func`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNL48UB8XubL"
      },
      "outputs": [],
      "source": [
        "# 해당 프롬프트 포맷은 phi-2 모델에 사용 가능\n",
        "# Phi-2 instruction-answer format: \"Instruct: <prompt>\\nOutput:\"\n",
        "\n",
        "prompt_template=\"\"\"Instruct: Answer to the question for the given clinical note.\n",
        "[note start]\n",
        "{note}\n",
        "[note end]\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Output: {answer}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_Eiy_-NcjKB"
      },
      "outputs": [],
      "source": [
        "print(prompt_template.format(note=\"xxx\", question=\"yyy\", answer=\"zzz\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjzfAox8cjKB"
      },
      "outputs": [],
      "source": [
        "# 샘플 데이터를 입력으로 받아 형식에 맞게 프롬프트를 구성하여 내보내는 함수\n",
        "def format_dataset(samples):\n",
        "    outputs = []\n",
        "    for _, note, question, answer, _ in zip(*samples.values()):\n",
        "        out = prompt_template.format(note=note, question=question, answer=answer)\n",
        "        outputs.append(out)\n",
        "    return outputs\n",
        "\n",
        "sample_input = format_dataset({k: [v] for k, v in dataset['train'][0].items()})[0]\n",
        "print(sample_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdmI7SJBcjKG"
      },
      "outputs": [],
      "source": [
        "# Sanity Check\n",
        "prompt_len = len(tokenizer.encode(prompt_template))\n",
        "if prompt_len > 180:\n",
        "    raise ValueError(f\"Your prompt is too long! Please reduce the length from {prompt_len} to 180 tokens\")\n",
        "print(f\"Prompt Length: {prompt_len} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F13qKP1RcjKG"
      },
      "source": [
        "### 프롬프트 데이터 입출력 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-F0CmI16j_l"
      },
      "outputs": [],
      "source": [
        "# 샘플 프롬프트 데이터 생성\n",
        "sample_idx = 10\n",
        "sample_data = dataset['train'][sample_idx]\n",
        "sample_fmt_data = format_dataset({k: [v] for k, v in sample_data.items()})\n",
        "print(sample_fmt_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fANevmlMcjKG"
      },
      "outputs": [],
      "source": [
        "# 샘플 프롬프트 입력 데이터 (input)\n",
        "sample_input = sample_fmt_data[0].split(\"Output: \")[0] + \"Output: \"\n",
        "print(sample_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ty1oUvmcjKG"
      },
      "outputs": [],
      "source": [
        "sample_output = sample_fmt_data[0].split(\"Output: \")[1]\n",
        "print(sample_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGyFa5JLcjKG"
      },
      "source": [
        "### 프롬프트 입력 후 출력 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liZTHmFJcjKG"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer.encode(sample_input, return_tensors='pt').to('cuda')\n",
        "\n",
        "# 모델을 사용하여 입력 시퀀스에 대한 출력 생성\n",
        "with torch.no_grad():\n",
        "  output = model.generate(\n",
        "      input_ids=input_ids,\n",
        "      max_length=512,\n",
        "      use_cache=True,\n",
        "      temperature=0.,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "# 생성된 출력을 디코딩하여 텍스트로 변환\n",
        "print(tokenizer.decode(output.to('cpu')[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWkYVHmxcjKH"
      },
      "outputs": [],
      "source": [
        "# 실제 Output에 해당하는 부분만 필터링\n",
        "print(tokenizer.decode(output.to('cpu')[0], skip_special_tokens=True).split(\"Output: \")[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_7mytyncjKH"
      },
      "source": [
        "### 학습할 데이터셋 정의  (`train_dataset`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bXTfKImbvEC"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATASET_SIZE = 2000\n",
        "train_dataset = dataset['train']\n",
        "sampled_train_dataset = train_dataset.select(range(TRAIN_DATASET_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Xp5EC3cjKH"
      },
      "source": [
        "### Data Collator 정의 (`data_collator`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67tLa-HZcjKH"
      },
      "outputs": [],
      "source": [
        "response_template = \"Output:\"\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjTFytK4-uUf"
      },
      "source": [
        "## [Step 5] 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wpzxdsWcjKH"
      },
      "source": [
        "### 학습 환경 세팅 (`LoraConfig`, `SFTConfig`, `SFTTrainer`)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "lora_config=LoraConfig(\n",
        "    r=4,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules= [\"Wqkv\", \"fc1\", \"fc2\" ]\n",
        ")\n",
        "\n",
        "sft_config = SFTConfig(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    fp16=True,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=1e-4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_strategy=\"no\",\n",
        "    warmup_ratio=0.03,\n",
        "    logging_steps=5,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    gradient_checkpointing=True,\n",
        "    max_seq_length=512,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=sft_config,\n",
        "    train_dataset=sampled_train_dataset,\n",
        "    formatting_func=format_dataset,\n",
        "    data_collator=collator,\n",
        "    peft_config=lora_config,\n",
        "    processing_class=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "NM-XhrAnmwUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습하기"
      ],
      "metadata": {
        "id": "wgibnNm5e0q4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_Ngq49_BA2E"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### huggingface에 모델 업로드하기"
      ],
      "metadata": {
        "id": "1p8BvjEBV_gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `huggingface-cli` 로그인"
      ],
      "metadata": {
        "id": "xkawImQ5WuHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login # TODO: you need a 'write' type token"
      ],
      "metadata": {
        "id": "1R8Zv5MHWGEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trainer 업로드하기"
      ],
      "metadata": {
        "id": "ia5pVScuWJz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "your_name = \"\" # TODO: huggingface id (e.g. \"Sujeongim\")\n",
        "trainer.push_to_hub(f\"{your_name}/kosaim2024-phi-2-asclepius\")"
      ],
      "metadata": {
        "id": "noi_h-zdWG9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 업로드한 모델 다운받기"
      ],
      "metadata": {
        "id": "BitwLHEFWNVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "## Copy & paste the code that hugging face suggested (click 'Use this model')\n",
        "your_name = \"\" # TODO: huggingface id (e.g., \"Sujeongim\")\n",
        "config = PeftConfig.from_pretrained(f\"{your_name}/results\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\")\n",
        "model = PeftModel.from_pretrained(base_model, f\"{your_name}/results\")"
      ],
      "metadata": {
        "id": "7LqvprEqWSk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm6t-hj6_IEy"
      },
      "source": [
        "## [Step 6] 모델 추론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmzDQxFRmwAW"
      },
      "source": [
        "\n",
        "\n",
        "- 데이터를 통해 테스트해볼 수 있는 task의 종류 및 각 task에 해당하는 예시 질문은 다음과 같습니다.\n",
        "\n",
        "- 질문 형식은 예시 질문에 국한될 필요는 없습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B72_yCLo1g_U"
      },
      "source": [
        "\n",
        "| <b>Task</b> | <b>Task 설명</b> |  <b>예시 질문</b> |\n",
        "|-----|-----|-----|\n",
        "|Named Entity Recognition|텍스트에서 사람, 장소, 조직 등 고유명사를 식별합니다.|- Can Named Entity Recognition identify any thrombophilia-related entities in this discharge summary? <br> <br> - What named entities related to COVID-19 infections can be identified through Named Entity Recognition in this discharge summary?|\n",
        "|Abbreviation Expansion|약어를 원래의 긴 형태로 확장합니다.| - What is the expanded form of the abbreviation 'CSF'? <br> <br> - What are the abbreviated terms in the given discharge summary that require expansion?|\n",
        "|Relation Extraction|텍스트에서 두 개체 간의 관계를 식별하고 추출합니다.|- What was the treatment provided to the patient with hypokalaemia, malnutrition, and decreased renal function, and how did it improve their symptoms? <br><br> - What is the relationship extracted between ipilimumab treatment and the patient's thyroid storm in the given discharge summary?|\n",
        "|Temporal Information Extraction|텍스트에서 날짜, 시간과 같은 시간 정보를 식별하고 추출합니다.|- When was the patient discharged following surgery? <br><br> - When did the patient first complain of swelling in the right sternoclavicular joint, and how long did it take to significantly resolve symptoms with therapy?|\n",
        "|Coreference Resolution|문맥에서 같은 대상을 가리키는 다른 표현(지시어)을 연결합니다.|- What coreferences are resolved in the hospital course section related to the patient's diagnosis of DHR? <br><br> - What pronouns or nouns in the hospital course section of the discharge summary were subject to coreference resolution and how were they resolved?|\n",
        "|Paraphrasing|문장을 다른 표현으로 바꾸어 재구성합니다.|- Can you rephrase the sentence \"The patient was deemed to have a guarded prognosis with multiorgan failure\" in a simpler way for a patient or family member to understand? <br><br> - How can the hospital course summary be paraphrased to make it more easily comprehensible for the patient and their family?|\n",
        "|Summarization|긴 텍스트에서 중요한 정보를 추출하여 짧게 요약합니다|- What is the summary of the patient's diagnosis and treatment during hospitalization and discharge? <br><br> - What was the primary diagnosis and treatment plan for the patient in the given discharge summary, and what persistent symptoms did they experience despite the treatment?|\n",
        "|Question Answering|텍스트를 기반으로 질문에 대한 답을 제공합니다.|- What was the patient diagnosed with and what treatment was chosen for his refractory ascites? <br><br> - What was the treatment plan for the patient's multi-system process, and how effective was it in achieving remission?|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_ntjMAe6Uoh"
      },
      "outputs": [],
      "source": [
        "# 비교 평가하기\n",
        "model = trainer.model\n",
        "model.eval()\n",
        "\n",
        "note_samples = train_dataset.select(range(len(train_dataset)-10, len(train_dataset)))['note']\n",
        "\n",
        "def inference(note, question, model):\n",
        "    prompt = prompt_template.format(note=note, question=question, answer=\"\")\n",
        "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to('cuda')\n",
        "    outs = model.generate(\n",
        "        input_ids=tokens,\n",
        "        max_length=512,\n",
        "        use_cache=True,\n",
        "        temperature=0.,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    output_text = tokenizer.decode(outs.to('cpu')[0], skip_special_tokens=True)\n",
        "    return output_text[len(prompt):]\n",
        "\n",
        "\n",
        "def compare_models(note, question):\n",
        "    with torch.no_grad():\n",
        "        asc_answer = inference(note, question, trainer.model)\n",
        "        with model.disable_adapter():\n",
        "            phi_answer = inference(note, question, trainer.model)\n",
        "    return asc_answer, phi_answer\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=compare_models,\n",
        "    inputs=[gr.Dropdown(note_samples), \"text\"],\n",
        "    outputs=[gr.Textbox(label=\"Asclepius\"), gr.Textbox(label=\"Phi-2\")]\n",
        ")\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VrNcgl2hJRH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}